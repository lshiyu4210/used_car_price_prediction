{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load imputed dataset\n",
    "X_other_imputed_xgb = pd.read_csv(\"../data/X_other_imputed_xgb.csv\")\n",
    "X_test_imputed_xgb = pd.read_csv(\"../data/X_test_imputed_xgb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3207,)\n",
      "(802,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load target variable\n",
    "y_other = pd.read_csv(\"../data/y_other.csv\").squeeze().to_numpy()\n",
    "y_test = pd.read_csv(\"../data/y_test.csv\").squeeze().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def MLpipeline(X_other, y_other, X_test, y_test, ML_algo, param_grid, scoring):\n",
    "    '''\n",
    "    This function directly uses the provided train, validation, and test splits.\n",
    "    It evaluates models using MAE, RMSE, and R², and records the best model for each metric.\n",
    "\n",
    "    Args:\n",
    "    - X_train, y_train: Training dataset\n",
    "    - X_val, y_val: Validation dataset for GridSearchCV\n",
    "    - X_test, y_test: Test dataset for evaluation\n",
    "    - ML_algo: Machine Learning algorithm\n",
    "    - param_grid: Parameter grid for hyperparameter tuning\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary containing test scores (MAE, RMSE, R²)\n",
    "    - The best model for each metric\n",
    "    '''\n",
    "    # Lists to store results\n",
    "    test_scores = {\n",
    "        'MAE': [],\n",
    "        'RMSE': [],\n",
    "        'R2': []\n",
    "    }\n",
    "\n",
    "    # GridSearchCV\n",
    "    print(\"\\nPerforming GridSearchCV...\")\n",
    "    grid = GridSearchCV(\n",
    "        estimator=ML_algo,\n",
    "        param_grid=param_grid,\n",
    "        scoring=scoring,  # Single scoring metric\n",
    "        refit=True,\n",
    "        cv=4,  # 4-fold cross-validation\n",
    "        return_train_score=True,\n",
    "        n_jobs=-1,\n",
    "        verbose=True\n",
    "    )\n",
    "    grid.fit(X_other, y_other)\n",
    "\n",
    "    # Save the best model\n",
    "    best_model = grid.best_estimator_\n",
    "    validation_score = -grid.best_score_ if 'neg' in scoring else grid.best_score_\n",
    "    print('Best model parameters:', grid.best_params_)\n",
    "    print(f'Validation score for {scoring}:', validation_score)\n",
    "\n",
    "    # Predictions and metrics on the test set\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_rmse = root_mean_squared_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    print('Test MAE:', test_mae)\n",
    "    print('Test RMSE:', test_rmse)\n",
    "    print('Test R²:', test_r2)\n",
    "\n",
    "    # Store test scores\n",
    "    test_scores = {\n",
    "        'MAE': test_mae,\n",
    "        'RMSE': test_rmse,\n",
    "        'R2': test_r2\n",
    "    }\n",
    "\n",
    "    # Return results\n",
    "    return test_scores, best_model, validation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Metrics:\n",
      "Baseline RMSE: 0.3833\n",
      "Baseline MAE: 0.2889\n",
      "Baseline R²: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "y_mean = np.mean(y_test)  # Baseline: Predict the mean for all instances\n",
    "baseline_rmse = root_mean_squared_error(y_test, [y_mean] * len(y_test))\n",
    "baseline_mae = mean_absolute_error(y_test, [y_mean] * len(y_test))\n",
    "baseline_r2 = r2_score(y_test, [y_mean] * len(y_test))\n",
    "\n",
    "print(\"Baseline Metrics:\")\n",
    "print(f\"Baseline RMSE: {baseline_rmse:.4f}\")\n",
    "print(f\"Baseline MAE: {baseline_mae:.4f}\")\n",
    "print(f\"Baseline R²: {baseline_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Parameter grids\n",
    "param_grids = {\n",
    "    'Lasso': {'alpha': [0.01, 0.1, 1, 10, 100]},\n",
    "    'Ridge': {'alpha': [0.01, 0.1, 1, 10, 100]},\n",
    "    'ElasticNet': {\n",
    "        'alpha': [0.01, 0.1, 1, 10, 100],\n",
    "        'l1_ratio': [0.2, 0.4, 0.6, 0.8]\n",
    "    },\n",
    "    'RandomForestRegressor': {\n",
    "        'max_depth': [1, 3, 10, 30, 100],\n",
    "        'max_features': [0.25, 0.5, 0.75, 1.0]\n",
    "    },\n",
    "    # 'SVR': {\n",
    "    #     'C': [0.1, 1, 10, 100],\n",
    "    #     'epsilon': [0.1, 0.2, 0.5],\n",
    "    #     'kernel': ['linear', 'rbf'],\n",
    "    #     'gamma': ['scale', 'auto', 0.01, 0.1, 1]\n",
    "    # },\n",
    "    'KNeighborsRegressor': {\n",
    "        'n_neighbors': [3, 5, 10, 20],\n",
    "        'weights': ['uniform', 'distance']\n",
    "    },\n",
    "    'XGBRegressor': {\n",
    "        'n_estimators': [50, 100, 150],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Models to train\n",
    "models = {\n",
    "    'Lasso': Lasso(),\n",
    "    'Ridge': Ridge(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'RandomForestRegressor': RandomForestRegressor(random_state=42),\n",
    "    # 'SVR': SVR(),\n",
    "    'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "    'XGBRegressor': XGBRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using scoring metric: neg_mean_absolute_error\n",
      "\n",
      "Training Lasso...\n",
      "\n",
      "Performing GridSearchCV...\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Best model parameters: {'alpha': 0.01}\n",
      "Validation score for neg_mean_absolute_error: 0.12842513368452407\n",
      "Test MAE: 0.129476189512615\n",
      "Test RMSE: 0.1972147845355382\n",
      "Test R²: 0.7352044595938109\n",
      "\n",
      "Training Ridge...\n",
      "\n",
      "Performing GridSearchCV...\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Best model parameters: {'alpha': 1}\n",
      "Validation score for neg_mean_absolute_error: 0.1066015768296514\n",
      "Test MAE: 0.11100750474710881\n",
      "Test RMSE: 0.17864719491602327\n",
      "Test R²: 0.7827178097071597\n",
      "\n",
      "Training ElasticNet...\n",
      "\n",
      "Performing GridSearchCV...\n",
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
      "Best model parameters: {'alpha': 0.01, 'l1_ratio': 0.2}\n",
      "Validation score for neg_mean_absolute_error: 0.1190792523725422\n",
      "Test MAE: 0.11982591739455209\n",
      "Test RMSE: 0.18673270589167684\n",
      "Test R²: 0.7626044855834969\n",
      "\n",
      "Training RandomForestRegressor...\n",
      "\n",
      "Performing GridSearchCV...\n",
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
      "Best model parameters: {'max_depth': 30, 'max_features': 0.25}\n",
      "Validation score for neg_mean_absolute_error: 0.09561010823821166\n",
      "Test MAE: 0.09324908054150625\n",
      "Test RMSE: 0.15585125468712438\n",
      "Test R²: 0.8346316726805222\n",
      "\n",
      "Training KNeighborsRegressor...\n",
      "\n",
      "Performing GridSearchCV...\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'n_neighbors': 10, 'weights': 'distance'}\n",
      "Validation score for neg_mean_absolute_error: 0.11148067350820007\n",
      "Test MAE: 0.11361792526927976\n",
      "Test RMSE: 0.17804847299106322\n",
      "Test R²: 0.7841717772931248\n",
      "\n",
      "Training XGBRegressor...\n",
      "\n",
      "Performing GridSearchCV...\n",
      "Fitting 4 folds for each of 27 candidates, totalling 108 fits\n",
      "Best model parameters: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 150}\n",
      "Validation score for neg_mean_absolute_error: 0.0904802017273792\n",
      "Test MAE: 0.08983420166799867\n",
      "Test RMSE: 0.15162792795095278\n",
      "Test R²: 0.8434726876805386\n",
      "\n",
      "Using scoring metric: neg_root_mean_squared_error\n",
      "\n",
      "Training Lasso...\n",
      "\n",
      "Performing GridSearchCV...\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Best model parameters: {'alpha': 0.01}\n",
      "Validation score for neg_root_mean_squared_error: 0.1796823351210273\n",
      "Test MAE: 0.129476189512615\n",
      "Test RMSE: 0.1972147845355382\n",
      "Test R²: 0.7352044595938109\n",
      "\n",
      "Training Ridge...\n",
      "\n",
      "Performing GridSearchCV...\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Best model parameters: {'alpha': 1}\n",
      "Validation score for neg_root_mean_squared_error: 0.1473415915958212\n",
      "Test MAE: 0.11100750474710881\n",
      "Test RMSE: 0.17864719491602327\n",
      "Test R²: 0.7827178097071597\n",
      "\n",
      "Training ElasticNet...\n",
      "\n",
      "Performing GridSearchCV...\n",
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
      "Best model parameters: {'alpha': 0.01, 'l1_ratio': 0.2}\n",
      "Validation score for neg_root_mean_squared_error: 0.16637593845193777\n",
      "Test MAE: 0.11982591739455209\n",
      "Test RMSE: 0.18673270589167684\n",
      "Test R²: 0.7626044855834969\n",
      "\n",
      "Training RandomForestRegressor...\n",
      "\n",
      "Performing GridSearchCV...\n",
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
      "Best model parameters: {'max_depth': 30, 'max_features': 0.25}\n",
      "Validation score for neg_root_mean_squared_error: 0.13452905701973736\n",
      "Test MAE: 0.09324908054150625\n",
      "Test RMSE: 0.15585125468712438\n",
      "Test R²: 0.8346316726805222\n",
      "\n",
      "Training KNeighborsRegressor...\n",
      "\n",
      "Performing GridSearchCV...\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'n_neighbors': 10, 'weights': 'distance'}\n",
      "Validation score for neg_root_mean_squared_error: 0.15478953916043575\n",
      "Test MAE: 0.11361792526927976\n",
      "Test RMSE: 0.17804847299106322\n",
      "Test R²: 0.7841717772931248\n",
      "\n",
      "Training XGBRegressor...\n",
      "\n",
      "Performing GridSearchCV...\n",
      "Fitting 4 folds for each of 27 candidates, totalling 108 fits\n",
      "Best model parameters: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 150}\n",
      "Validation score for neg_root_mean_squared_error: 0.12766444753951256\n",
      "Test MAE: 0.08983420166799867\n",
      "Test RMSE: 0.15162792795095278\n",
      "Test R²: 0.8434726876805386\n",
      "\n",
      "Using scoring metric: r2\n",
      "\n",
      "Training Lasso...\n",
      "\n",
      "Performing GridSearchCV...\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Best model parameters: {'alpha': 0.01}\n",
      "Validation score for r2: 0.7581037567583551\n",
      "Test MAE: 0.129476189512615\n",
      "Test RMSE: 0.1972147845355382\n",
      "Test R²: 0.7352044595938109\n",
      "\n",
      "Training Ridge...\n",
      "\n",
      "Performing GridSearchCV...\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Best model parameters: {'alpha': 1}\n",
      "Validation score for r2: 0.8373569325869518\n",
      "Test MAE: 0.11100750474710881\n",
      "Test RMSE: 0.17864719491602327\n",
      "Test R²: 0.7827178097071597\n",
      "\n",
      "Training ElasticNet...\n",
      "\n",
      "Performing GridSearchCV...\n",
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
      "Best model parameters: {'alpha': 0.01, 'l1_ratio': 0.2}\n",
      "Validation score for r2: 0.7925982287597727\n",
      "Test MAE: 0.11982591739455209\n",
      "Test RMSE: 0.18673270589167684\n",
      "Test R²: 0.7626044855834969\n",
      "\n",
      "Training RandomForestRegressor...\n",
      "\n",
      "Performing GridSearchCV...\n",
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
      "Best model parameters: {'max_depth': 30, 'max_features': 0.25}\n",
      "Validation score for r2: 0.8642813565182084\n",
      "Test MAE: 0.09324908054150625\n",
      "Test RMSE: 0.15585125468712438\n",
      "Test R²: 0.8346316726805222\n",
      "\n",
      "Training KNeighborsRegressor...\n",
      "\n",
      "Performing GridSearchCV...\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'n_neighbors': 10, 'weights': 'distance'}\n",
      "Validation score for r2: 0.8204555700258949\n",
      "Test MAE: 0.11361792526927976\n",
      "Test RMSE: 0.17804847299106322\n",
      "Test R²: 0.7841717772931248\n",
      "\n",
      "Training XGBRegressor...\n",
      "\n",
      "Performing GridSearchCV...\n",
      "Fitting 4 folds for each of 27 candidates, totalling 108 fits\n",
      "Best model parameters: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 150}\n",
      "Validation score for r2: 0.8777472681446291\n",
      "Test MAE: 0.08983420166799867\n",
      "Test RMSE: 0.15162792795095278\n",
      "Test R²: 0.8434726876805386\n",
      "\n",
      "Best Overall Models:\n",
      "MAE - Method: XGBRegressor, Value: 0.0898\n",
      "RMSE - Method: XGBRegressor, Value: 0.1516\n",
      "R2 - Method: XGBRegressor, Value: 0.8435\n"
     ]
    }
   ],
   "source": [
    "# Initialize results dictionary and track best overall models\n",
    "results = {}\n",
    "best_models_overall = {\n",
    "    'MAE': {'method': None, 'model': None, 'value': float('inf')},  # Lower is better\n",
    "    'RMSE': {'method': None, 'model': None, 'value': float('inf')},  # Lower is better\n",
    "    'R2': {'method': None, 'model': None, 'value': float('-inf')}   # Higher is better\n",
    "}\n",
    "scorings = ['neg_mean_absolute_error', 'neg_root_mean_squared_error', 'r2']\n",
    "\n",
    "# Training pipeline\n",
    "for s in scorings:\n",
    "    print(f\"\\nUsing scoring metric: {s}\")\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nTraining {model_name}...\")\n",
    "        try:\n",
    "            test_scores, best_model, validation_score = MLpipeline(\n",
    "                X_other_imputed_xgb, y_other, X_test_imputed_xgb, y_test, model, param_grids[model_name], s\n",
    "            )\n",
    "            # Save results for each model\n",
    "            results[model_name] = results.get(model_name, {})\n",
    "            results[model_name][s] = {\n",
    "                'Best Parameters': best_model.get_params(),\n",
    "                'Validation': validation_score,\n",
    "                'Test MAE': test_scores['MAE'],\n",
    "                'Test RMSE': test_scores['RMSE'],\n",
    "                'Test R²': test_scores['R2']\n",
    "            }\n",
    "\n",
    "            # Update best overall models for each metric\n",
    "            if test_scores['MAE'] < best_models_overall['MAE']['value']:\n",
    "                best_models_overall['MAE'] = {'method': model_name, 'model': best_model, 'value': test_scores['MAE']}\n",
    "            if test_scores['RMSE'] < best_models_overall['RMSE']['value']:\n",
    "                best_models_overall['RMSE'] = {'method': model_name, 'model': best_model, 'value': test_scores['RMSE']}\n",
    "            if test_scores['R2'] > best_models_overall['R2']['value']:\n",
    "                best_models_overall['R2'] = {'method': model_name, 'model': best_model, 'value': test_scores['R2']}\n",
    "        except Exception as e:\n",
    "            print(f\"Error training {model_name} with scoring {s}: {e}\")\n",
    "\n",
    "# Print the best overall models for each metric\n",
    "print(\"\\nBest Overall Models:\")\n",
    "for metric, info in best_models_overall.items():\n",
    "    print(f\"{metric} - Method: {info['method']}, Value: {info['value']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results as a text file\n",
    "with open(\"../results/xgb_imputed_best_models_results.txt\", \"w\") as f:\n",
    "    # Write detailed results for each model\n",
    "    f.write(\"Detailed Results for Each Model:\\n\\n\")\n",
    "    for model_name, model_results in results.items():\n",
    "        f.write(f\"Model: {model_name}\\n\")\n",
    "        for scoring_metric, metrics in model_results.items():\n",
    "            f.write(f\"  Scoring Metric: {scoring_metric}\\n\")\n",
    "            f.write(f\"    Best Parameters: {metrics['Best Parameters']}\\n\")\n",
    "            f.write(f\"    Validation Score: {metrics['Validation']:.4f}\\n\")\n",
    "            f.write(f\"    Test MAE: {metrics['Test MAE']:.4f}\\n\")\n",
    "            f.write(f\"    Test RMSE: {metrics['Test RMSE']:.4f}\\n\")\n",
    "            f.write(f\"    Test R²: {metrics['Test R²']:.4f}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    # Write the best overall models\n",
    "    f.write(\"Best Overall Models:\\n\")\n",
    "    for metric, info in best_models_overall.items():\n",
    "        f.write(f\"{metric} - Method: {info['method']}, Value: {info['value']:.4f}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
