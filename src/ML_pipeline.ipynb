{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4009, 15)\n"
     ]
    }
   ],
   "source": [
    "# Import Data\n",
    "import pandas as pd\n",
    "\n",
    "new_used_car = pd.read_csv(\"../data/processed_used_car.csv\")\n",
    "random_state = 42\n",
    "\n",
    "y = new_used_car['sales_price_log']\n",
    "X = new_used_car.drop(['price', 'sales_price_log'], axis=1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: brand, Data Type: object\n",
      "Column: model, Data Type: object\n",
      "Column: model_year, Data Type: int64\n",
      "Column: milage, Data Type: int64\n",
      "Column: fuel_type, Data Type: object\n",
      "Column: ext_col, Data Type: object\n",
      "Column: int_col, Data Type: object\n",
      "Column: accident, Data Type: object\n",
      "Column: clean_title, Data Type: object\n",
      "Column: horsepower, Data Type: float64\n",
      "Column: displacement, Data Type: float64\n",
      "Column: cylinders, Data Type: float64\n",
      "Column: turbo, Data Type: bool\n",
      "Column: transmission_type, Data Type: object\n",
      "Column: gears, Data Type: float64\n"
     ]
    }
   ],
   "source": [
    "# Data types of features\n",
    "for column in new_used_car.columns:\n",
    "    print(f\"Column: {column}, Data Type: {new_used_car[column].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction of missing values in features:\n",
      "fuel_type            0.054128\n",
      "accident             0.028187\n",
      "clean_title          0.148666\n",
      "horsepower           0.201547\n",
      "displacement         0.054128\n",
      "cylinders            0.109753\n",
      "transmission_type    0.121976\n",
      "gears                0.457221\n",
      "dtype: float64\n",
      "data types of the features with missing values:\n",
      "fuel_type             object\n",
      "accident              object\n",
      "clean_title           object\n",
      "horsepower           float64\n",
      "displacement         float64\n",
      "cylinders            float64\n",
      "transmission_type     object\n",
      "gears                float64\n",
      "dtype: object\n",
      "fraction of points with missing values: 0.6083811424295336\n"
     ]
    }
   ],
   "source": [
    "# Inspect Missing Value\n",
    "perc_missing_per_ftr = new_used_car.isnull().sum(axis=0)/new_used_car.shape[0]\n",
    "print('fraction of missing values in features:')\n",
    "print(perc_missing_per_ftr[perc_missing_per_ftr > 0])\n",
    "print('data types of the features with missing values:')\n",
    "print(new_used_car[perc_missing_per_ftr[perc_missing_per_ftr > 0].index].dtypes)\n",
    "frac_missing = sum(new_used_car.isnull().sum(axis=1)!=0)/new_used_car.shape[0]\n",
    "print('fraction of points with missing values:',frac_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2405, 15)\n",
      "(802, 15)\n",
      "(802, 15)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split to train, CV, and test\n",
    "X_train, X_other, y_train, y_other = train_test_split(X, y, train_size=0.6, random_state=random_state)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_other, y_other, test_size=0.5, random_state=random_state)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group features into numerical and categorical variables\n",
    "num_ftrs = ['model_year', 'milage', 'horsepower', 'displacement', 'cylinders', 'turbo', 'gears']\n",
    "cat_ftrs = ['brand', 'model', 'fuel_type', 'ext_col', 'int_col', 'accident', 'clean_title', 'transmission_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Preprocess\n",
    "# one-hot encoder for categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(sparse_output=False,handle_unknown='ignore'))])\n",
    "\n",
    "# standard scaler for numerical variables\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# collect the transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_ftrs),\n",
    "        ('cat', categorical_transformer, cat_ftrs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2405, 1777)\n",
      "(802, 1777)\n",
      "(802, 1777)\n",
      "['num__model_year' 'num__milage' 'num__horsepower' ...\n",
      " 'cat__transmission_type_Automatic' 'cat__transmission_type_Manual'\n",
      " 'cat__transmission_type_nan']\n"
     ]
    }
   ],
   "source": [
    "# fit_transform the training set\n",
    "X_prep = preprocessor.fit_transform(X_train)\n",
    "# the feature names after fit\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "# you can convert the numpy array back to a data frame with the feature names if you want\n",
    "df_train = pd.DataFrame(data=X_prep,columns=feature_names)\n",
    "print(df_train.shape)\n",
    "\n",
    "# transform the CV\n",
    "df_val = preprocessor.transform(X_val)\n",
    "df_val = pd.DataFrame(data=df_val,columns = feature_names)\n",
    "print(df_val.shape)\n",
    "\n",
    "# transform the test\n",
    "df_test = preprocessor.transform(X_test)\n",
    "df_test = pd.DataFrame(data=df_test,columns = feature_names)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimensions: (2405, 1777)\n",
      "fraction of missing values in features:\n",
      "num__horsepower      0.200416\n",
      "num__displacement    0.050728\n",
      "num__cylinders       0.111435\n",
      "num__gears           0.456549\n",
      "dtype: float64\n",
      "data types of the features with missing values:\n",
      "num__horsepower      float64\n",
      "num__displacement    float64\n",
      "num__cylinders       float64\n",
      "num__gears           float64\n",
      "dtype: object\n",
      "fraction of points with missing values: 0.59002079002079\n"
     ]
    }
   ],
   "source": [
    "# Missing Value of training set After transformation\n",
    "print('data dimensions:',df_train.shape)\n",
    "perc_missing_per_ftr = df_train.isnull().sum(axis=0)/df_train.shape[0]\n",
    "print('fraction of missing values in features:')\n",
    "print(perc_missing_per_ftr[perc_missing_per_ftr > 0])\n",
    "print('data types of the features with missing values:')\n",
    "print(df_train[perc_missing_per_ftr[perc_missing_per_ftr > 0].index].dtypes)\n",
    "frac_missing = sum(df_train.isnull().sum(axis=1)!=0)/df_train.shape[0]\n",
    "print('fraction of points with missing values:',frac_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of missing values per feature in the training set:\n",
      "num__horsepower      0.200416\n",
      "num__displacement    0.050728\n",
      "num__cylinders       0.111435\n",
      "num__gears           0.456549\n",
      "dtype: float64\n",
      "Proportion of rows with missing values in the training set: 0.59002079002079\n",
      "Proportion of missing values per feature in the validation set:\n",
      "num__horsepower      0.209476\n",
      "num__displacement    0.061097\n",
      "num__cylinders       0.108479\n",
      "num__gears           0.441397\n",
      "dtype: float64\n",
      "Proportion of rows with missing values in the validation set: 0.5922693266832918\n",
      "Proportion of missing values per feature in the test set:\n",
      "num__horsepower      0.197007\n",
      "num__displacement    0.057357\n",
      "num__cylinders       0.105985\n",
      "num__gears           0.475062\n",
      "dtype: float64\n",
      "Proportion of rows with missing values in the test set: 0.6159600997506235\n"
     ]
    }
   ],
   "source": [
    "# Check missing values for each feature (column) in the training set\n",
    "perc_missing_per_ftr_train = df_train.isnull().sum(axis=0) / df_train.shape[0]\n",
    "print('Proportion of missing values per feature in the training set:')\n",
    "print(perc_missing_per_ftr_train[perc_missing_per_ftr_train > 0])\n",
    "\n",
    "# Check the proportion of rows with missing values in the training set\n",
    "frac_missing_train = (df_train.isnull().sum(axis=1) != 0).mean()\n",
    "print('Proportion of rows with missing values in the training set:', frac_missing_train)\n",
    "\n",
    "# Repeat for validation set\n",
    "perc_missing_per_ftr_val = df_val.isnull().sum(axis=0) / df_val.shape[0]\n",
    "print('Proportion of missing values per feature in the validation set:')\n",
    "print(perc_missing_per_ftr_val[perc_missing_per_ftr_val > 0])\n",
    "\n",
    "frac_missing_val = (df_val.isnull().sum(axis=1) != 0).mean()\n",
    "print('Proportion of rows with missing values in the validation set:', frac_missing_val)\n",
    "\n",
    "# Repeat for test set\n",
    "perc_missing_per_ftr_test = df_test.isnull().sum(axis=0) / df_test.shape[0]\n",
    "print('Proportion of missing values per feature in the test set:')\n",
    "print(perc_missing_per_ftr_test[perc_missing_per_ftr_test > 0])\n",
    "\n",
    "frac_missing_test = (df_test.isnull().sum(axis=1) != 0).mean()\n",
    "print('Proportion of rows with missing values in the test set:', frac_missing_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of missing values per feature across all sets:\n",
      "num__horsepower      0.201547\n",
      "num__displacement    0.054128\n",
      "num__cylinders       0.109753\n",
      "num__gears           0.457221\n",
      "dtype: float64\n",
      "Proportion of rows with missing values across all sets: 0.595659765527563\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the training, validation, and test sets\n",
    "df_combined = pd.concat([df_train, df_val, df_test], ignore_index=True)\n",
    "\n",
    "# Calculate the proportion of missing values per feature across all datasets\n",
    "perc_missing_per_ftr_combined = df_combined.isnull().sum(axis=0) / df_combined.shape[0]\n",
    "print('Proportion of missing values per feature across all sets:')\n",
    "print(perc_missing_per_ftr_combined[perc_missing_per_ftr_combined > 0])\n",
    "\n",
    "# Calculate the proportion of rows with missing values across all datasets\n",
    "frac_missing_combined = (df_combined.isnull().sum(axis=1) != 0).mean()\n",
    "print('Proportion of rows with missing values across all sets:', frac_missing_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def report_missing_values(preprocessor, X_train, X_val, X_test):\n",
    "    \"\"\"\n",
    "    Reports the proportion of missing values per feature and per row for\n",
    "    training, validation, test, and combined datasets after preprocessing.\n",
    "    \n",
    "    Args:\n",
    "        preprocessor: The preprocessing pipeline that transforms the data.\n",
    "        X_train: The training set before transformation.\n",
    "        X_val: The validation set before transformation.\n",
    "        X_test: The test set before transformation.\n",
    "    \n",
    "    Returns:\n",
    "        A dictionary with missing value statistics for training, validation,\n",
    "        test, and combined datasets.\n",
    "    \"\"\"\n",
    "    # Fit-transform training set\n",
    "    X_prep_train = preprocessor.fit_transform(X_train)\n",
    "    feature_names = preprocessor.get_feature_names_out()\n",
    "    df_train = pd.DataFrame(data=X_prep_train, columns=feature_names)\n",
    "\n",
    "    # Transform validation and test sets\n",
    "    df_val = pd.DataFrame(data=preprocessor.transform(X_val), columns=feature_names)\n",
    "    df_test = pd.DataFrame(data=preprocessor.transform(X_test), columns=feature_names)\n",
    "\n",
    "    # Combine datasets\n",
    "    df_combined = pd.concat([df_train, df_val, df_test], ignore_index=True)\n",
    "\n",
    "    # Helper function to calculate missing value statistics\n",
    "    def calculate_missing_stats(df, name):\n",
    "        perc_missing_per_ftr = df.isnull().sum(axis=0) / df.shape[0]\n",
    "        frac_missing_rows = (df.isnull().sum(axis=1) != 0).mean()\n",
    "        return {\n",
    "            'feature_missing_proportion': perc_missing_per_ftr[perc_missing_per_ftr > 0],\n",
    "            'row_missing_proportion': frac_missing_rows\n",
    "        }\n",
    "\n",
    "    # Calculate missing value statistics\n",
    "    missing_stats = {\n",
    "        'training': calculate_missing_stats(df_train, 'Training'),\n",
    "        'validation': calculate_missing_stats(df_val, 'Validation'),\n",
    "        'test': calculate_missing_stats(df_test, 'Test'),\n",
    "        'combined': calculate_missing_stats(df_combined, 'Combined')\n",
    "    }\n",
    "\n",
    "    # Print results\n",
    "    for dataset, stats in missing_stats.items():\n",
    "        print(f\"\\n{dataset.capitalize()} Dataset:\")\n",
    "        print(f\"Proportion of missing values per feature:\")\n",
    "        print(stats['feature_missing_proportion'])\n",
    "        print(f\"Proportion of rows with missing values: {stats['row_missing_proportion']:.4f}\")\n",
    "\n",
    "    return missing_stats\n",
    "\n",
    "# Example Usage\n",
    "missing_stats = report_missing_values(preprocessor, X_train, X_val, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def impute_with_xgboost_tuning(df, target_column, exclude_column):\n",
    "    \"\"\"\n",
    "    Impute missing values in a single column using XGBoost with hyperparameter tuning.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataset with missing values.\n",
    "        target_column (str): The column to impute.\n",
    "        exclude_column (str): The column to exclude from features (e.g., the target column).\n",
    "    \n",
    "    Returns:\n",
    "        pd.Series: The column with imputed values.\n",
    "    \"\"\"\n",
    "    # Separate rows with and without missing values in the target column\n",
    "    train_data = df[df[target_column].notnull()]\n",
    "    missing_data = df[df[target_column].isnull()]\n",
    "    \n",
    "    # If no missing values, return the column as-is\n",
    "    if missing_data.empty:\n",
    "        return df[target_column]\n",
    "    \n",
    "    # Define features (exclude target_column and exclude_column)\n",
    "    X_train = train_data.drop(columns=[target_column, exclude_column], errors='ignore')\n",
    "    y_train = train_data[target_column]\n",
    "    X_missing = missing_data.drop(columns=[target_column, exclude_column], errors='ignore')\n",
    "    \n",
    "    # Define the model and parameter grid\n",
    "    model = XGBRegressor(random_state=42)\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.3],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0]\n",
    "    }\n",
    "    \n",
    "    # Use GridSearchCV to find the best parameters\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(f\"Best parameters for {target_column}: {grid_search.best_params_}\")\n",
    "    \n",
    "    # Predict missing values\n",
    "    imputed_values = best_model.predict(X_missing)\n",
    "    \n",
    "    # Replace missing values with predictions\n",
    "    df.loc[df[target_column].isnull(), target_column] = imputed_values\n",
    "    \n",
    "    return df[target_column]\n",
    "\n",
    "# Impute all columns with missing values except the target column (sales_price_log)\n",
    "for col in new_used_car.columns:\n",
    "    if new_used_car[col].isnull().any() and col != 'sales_price_log':\n",
    "        print(f\"Imputing missing values for column: {col}\")\n",
    "        new_used_car[col] = impute_with_xgboost_tuning(new_used_car, col, 'sales_price_log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def MLpipeline(X, y, preprocessor, ML_algo, param_grid):\n",
    "    '''\n",
    "    This function splits the data into other/test (80/20) and then applies KFold with 4 folds to other.\n",
    "    It evaluates models using MAE, RMSE, and R², and records the best model for each metric.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary containing test scores (MAE, RMSE, R²) for each iteration\n",
    "    - The best model for each metric\n",
    "    '''\n",
    "\n",
    "    # Lists to store results\n",
    "    test_scores = {\n",
    "        'MAE': [],\n",
    "        'RMSE': [],\n",
    "        'R2': []\n",
    "    }\n",
    "    best_models = {\n",
    "        'MAE': None,\n",
    "        'RMSE': None,\n",
    "        'R2': None\n",
    "    }\n",
    "    best_scores = {\n",
    "        'MAE': float('inf'),\n",
    "        'RMSE': float('inf'),\n",
    "        'R2': float('-inf')\n",
    "    }\n",
    "\n",
    "    nr_states = 10\n",
    "\n",
    "    for i in range(nr_states):\n",
    "        print(f\"\\nIteration {i+1}\")\n",
    "\n",
    "        # Split data\n",
    "        X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state=42 * i)\n",
    "\n",
    "        # Create KFold object\n",
    "        kf = KFold(n_splits=4, shuffle=True, random_state=42 * i)\n",
    "\n",
    "        # Pipeline and GridSearchCV\n",
    "        pipe = make_pipeline(preprocessor, ML_algo)\n",
    "        grid = GridSearchCV(\n",
    "            pipe,\n",
    "            param_grid=param_grid,\n",
    "            scoring='neg_root_mean_squared_error',  # Primary metric for GridSearch\n",
    "            cv=kf,\n",
    "            return_train_score=True,\n",
    "            n_jobs=-1,\n",
    "            verbose=True\n",
    "        )\n",
    "        grid.fit(X_other, y_other)\n",
    "\n",
    "        # Save the best model\n",
    "        best_model = grid.best_estimator_\n",
    "        print('Best model parameters:', grid.best_params_)\n",
    "        print('Validation score (RMSE):', -grid.best_score_)\n",
    "\n",
    "        # Predictions and metrics on the test set\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "        test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "        test_rmse = root_mean_squared_error(y_test, y_test_pred)  # RMSE\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "        print('Test MAE:', test_mae)\n",
    "        print('Test RMSE:', test_rmse)\n",
    "        print('Test R²:', test_r2)\n",
    "\n",
    "        # Append test scores\n",
    "        test_scores['MAE'].append(test_mae)\n",
    "        test_scores['RMSE'].append(test_rmse)\n",
    "        test_scores['R2'].append(test_r2)\n",
    "\n",
    "        # Update best models\n",
    "        if test_mae < best_scores['MAE']:\n",
    "            best_scores['MAE'] = test_mae\n",
    "            best_models['MAE'] = best_model\n",
    "\n",
    "        if test_rmse < best_scores['RMSE']:\n",
    "            best_scores['RMSE'] = test_rmse\n",
    "            best_models['RMSE'] = best_model\n",
    "\n",
    "        if test_r2 > best_scores['R2']:\n",
    "            best_scores['R2'] = test_r2\n",
    "            best_models['R2'] = best_model\n",
    "\n",
    "    # Return results\n",
    "    return test_scores, best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Lasso\n",
      "\n",
      "Iteration 1\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 20 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n20 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py\", line 980, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1064, in check_array\n    _assert_all_finite(\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLasso does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 53\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 53\u001b[0m     test_scores, best_models \u001b[38;5;241m=\u001b[39m \u001b[43mMLpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocessor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grids\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# Calculate metrics\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     mean_mae \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(test_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[10], line 54\u001b[0m, in \u001b[0;36mMLpipeline\u001b[0;34m(X, y, preprocessor, ML_algo, param_grid)\u001b[0m\n\u001b[1;32m     44\u001b[0m pipe \u001b[38;5;241m=\u001b[39m make_pipeline(preprocessor, ML_algo)\n\u001b[1;32m     45\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     46\u001b[0m     pipe,\n\u001b[1;32m     47\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     53\u001b[0m )\n\u001b[0;32m---> 54\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_other\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_other\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Save the best model\u001b[39;00m\n\u001b[1;32m     57\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m~/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1014\u001b[0m     )\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1018\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1572\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:995\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    993\u001b[0m     )\n\u001b[0;32m--> 995\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 20 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n20 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py\", line 980, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1064, in check_array\n    _assert_all_finite(\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLasso does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Parameter grids\n",
    "param_grids = {\n",
    "    'Lasso': {'lasso__alpha': [0.01, 0.1, 1, 10, 100]},\n",
    "    'Ridge': {'ridge__alpha': [0.01, 0.1, 1, 10, 100]},\n",
    "    'ElasticNet': {\n",
    "        'elasticnet__alpha': [0.01, 0.1, 1, 10, 100],\n",
    "        'elasticnet__l1_ratio': [0.2, 0.4, 0.6, 0.8]\n",
    "    },\n",
    "    'RandomForestRegressor': {\n",
    "        'randomforestregressor__max_depth': [1, 3, 10, 30, 100],\n",
    "        'randomforestregressor__max_features': [0.25, 0.5, 0.75, 1.0]\n",
    "    },\n",
    "    'SVR': {\n",
    "        'svr__C': [0.1, 1, 10, 100],\n",
    "        'svr__epsilon': [0.1, 0.2, 0.5],\n",
    "        'svr__kernel': ['linear', 'rbf'],\n",
    "        'svr__gamma': ['scale', 'auto', 0.01, 0.1, 1]\n",
    "    },\n",
    "    'KNeighborsRegressor': {\n",
    "        'kneighborsregressor__n_neighbors': [3, 5, 10, 20],\n",
    "        'kneighborsregressor__weights': ['uniform', 'distance']\n",
    "    },\n",
    "    'XGBRegressor': {\n",
    "        'classifier__n_estimators': [50, 100, 150],\n",
    "        'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'classifier__max_depth': [3, 5, 7]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Models to train\n",
    "models = {\n",
    "    'Lasso': Lasso(),\n",
    "    'Ridge': Ridge(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'RandomForestRegressor': RandomForestRegressor(random_state=42),\n",
    "    'SVR': SVR(),\n",
    "    'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "    'XGBRegressor': XGBRegressor()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Training pipeline\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining {model_name}\")\n",
    "    test_scores, best_models = MLpipeline(X, y, preprocessor, model, param_grids[model_name])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mean_mae = np.mean(test_scores['MAE'])\n",
    "    std_mae = np.std(test_scores['MAE'])\n",
    "    mean_rmse = np.mean(test_scores['RMSE'])\n",
    "    std_rmse = np.std(test_scores['RMSE'])\n",
    "    mean_r2 = np.mean(test_scores['R2'])\n",
    "    std_r2 = np.std(test_scores['R2'])\n",
    "\n",
    "    # Store results\n",
    "    results[model_name] = {\n",
    "        'mean_mae': mean_mae,\n",
    "        'std_mae': std_mae,\n",
    "        'mean_rmse': mean_rmse,\n",
    "        'std_rmse': std_rmse,\n",
    "        'mean_r2': mean_r2,\n",
    "        'std_r2': std_r2,\n",
    "        'best_models': best_models\n",
    "    }\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"\\n{model_name} Metrics:\")\n",
    "    print(f\"Mean MAE: {mean_mae:.4f}, Std MAE: {std_mae:.4f}\")\n",
    "    print(f\"Mean RMSE: {mean_rmse:.4f}, Std RMSE: {std_rmse:.4f}\")\n",
    "    print(f\"Mean R²: {mean_r2:.4f}, Std R²: {std_r2:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
