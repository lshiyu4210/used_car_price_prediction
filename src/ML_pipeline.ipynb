{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4009, 12)\n"
     ]
    }
   ],
   "source": [
    "# Import Data\n",
    "import pandas as pd\n",
    "\n",
    "new_used_car = pd.read_csv(\"../data/processed_used_car.csv\")\n",
    "random_state = 42\n",
    "\n",
    "y = new_used_car['sales_price_log']\n",
    "# X = new_used_car.drop(['price', 'sales_price_log'], axis=1)\n",
    "X = new_used_car.drop(['price', 'sales_price_log', 'model', 'int_col', 'ext_col'], axis=1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: brand, Data Type: object\n",
      "Column: model, Data Type: object\n",
      "Column: model_year, Data Type: int64\n",
      "Column: milage, Data Type: int64\n",
      "Column: fuel_type, Data Type: object\n",
      "Column: ext_col, Data Type: object\n",
      "Column: int_col, Data Type: object\n",
      "Column: accident, Data Type: object\n",
      "Column: clean_title, Data Type: object\n",
      "Column: price, Data Type: int64\n",
      "Column: horsepower, Data Type: float64\n",
      "Column: displacement, Data Type: float64\n",
      "Column: cylinders, Data Type: float64\n",
      "Column: turbo, Data Type: bool\n",
      "Column: transmission_type, Data Type: object\n",
      "Column: gears, Data Type: float64\n",
      "Column: sales_price_log, Data Type: float64\n"
     ]
    }
   ],
   "source": [
    "# Data types of features\n",
    "for column in new_used_car.columns:\n",
    "    print(f\"Column: {column}, Data Type: {new_used_car[column].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction of missing values in features:\n",
      "fuel_type            0.054128\n",
      "accident             0.028187\n",
      "clean_title          0.148666\n",
      "horsepower           0.201547\n",
      "displacement         0.054128\n",
      "cylinders            0.109753\n",
      "transmission_type    0.121976\n",
      "gears                0.457221\n",
      "dtype: float64\n",
      "data types of the features with missing values:\n",
      "fuel_type             object\n",
      "accident              object\n",
      "clean_title           object\n",
      "horsepower           float64\n",
      "displacement         float64\n",
      "cylinders            float64\n",
      "transmission_type     object\n",
      "gears                float64\n",
      "dtype: object\n",
      "fraction of points with missing values: 0.6083811424295336\n"
     ]
    }
   ],
   "source": [
    "# Inspect Missing Values\n",
    "perc_missing_per_ftr = new_used_car.isnull().sum(axis=0)/new_used_car.shape[0]\n",
    "print('fraction of missing values in features:')\n",
    "print(perc_missing_per_ftr[perc_missing_per_ftr > 0])\n",
    "print('data types of the features with missing values:')\n",
    "print(new_used_car[perc_missing_per_ftr[perc_missing_per_ftr > 0].index].dtypes)\n",
    "frac_missing = sum(new_used_car.isnull().sum(axis=1)!=0)/new_used_car.shape[0]\n",
    "print('fraction of points with missing values:',frac_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2405, 12)\n",
      "(802, 12)\n",
      "(802, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split to train, CV, and test\n",
    "X_train, X_other, y_train, y_other = train_test_split(X, y, train_size=0.6, random_state=random_state)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_other, y_other, test_size=0.5, random_state=random_state)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group features into numerical and categorical variables\n",
    "num_ftrs = ['model_year', 'milage', 'horsepower', 'displacement', 'cylinders', 'turbo', 'gears']\n",
    "cat_ftrs = ['brand', 'fuel_type', 'accident', 'clean_title', 'transmission_type']\n",
    "# cat_ftrs = ['brand', 'fuel_type', 'model', 'ext_col', 'int_col', 'accident', 'clean_title', 'transmission_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Preprocess\n",
    "# one-hot encoder for categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(sparse_output=False,handle_unknown='ignore'))])\n",
    "\n",
    "# standard scaler for numerical variables\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# collect the transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_ftrs),\n",
    "        ('cat', categorical_transformer, cat_ftrs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set after preprocessing: (2405, 75)\n",
      "Shape of validation set after preprocessing: (802, 75)\n",
      "Shape of test set after preprocessing: (802, 75)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Fit-transform training set\n",
    "X_prep_train = preprocessor.fit_transform(X_train)\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "df_train = pd.DataFrame(data=X_prep_train, columns=feature_names)\n",
    "\n",
    "# Transform validation and test sets\n",
    "df_val = pd.DataFrame(data=preprocessor.transform(X_val), columns=feature_names)\n",
    "df_test = pd.DataFrame(data=preprocessor.transform(X_test), columns=feature_names)\n",
    "\n",
    "# Print shapes of the datasets\n",
    "print(f\"Shape of training set after preprocessing: {df_train.shape}\")\n",
    "print(f\"Shape of validation set after preprocessing: {df_val.shape}\")\n",
    "print(f\"Shape of test set after preprocessing: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Dataset:\n",
      "Proportion of missing values per feature:\n",
      "num__horsepower      0.200416\n",
      "num__displacement    0.050728\n",
      "num__cylinders       0.111435\n",
      "num__gears           0.456549\n",
      "dtype: float64\n",
      "Proportion of rows with missing values: 0.5900\n",
      "\n",
      "Validation Dataset:\n",
      "Proportion of missing values per feature:\n",
      "num__horsepower      0.209476\n",
      "num__displacement    0.061097\n",
      "num__cylinders       0.108479\n",
      "num__gears           0.441397\n",
      "dtype: float64\n",
      "Proportion of rows with missing values: 0.5923\n",
      "\n",
      "Test Dataset:\n",
      "Proportion of missing values per feature:\n",
      "num__horsepower      0.197007\n",
      "num__displacement    0.057357\n",
      "num__cylinders       0.105985\n",
      "num__gears           0.475062\n",
      "dtype: float64\n",
      "Proportion of rows with missing values: 0.6160\n",
      "\n",
      "Combined Dataset:\n",
      "Proportion of missing values per feature:\n",
      "num__horsepower      0.201547\n",
      "num__displacement    0.054128\n",
      "num__cylinders       0.109753\n",
      "num__gears           0.457221\n",
      "dtype: float64\n",
      "Proportion of rows with missing values: 0.5957\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def report_missing_values(df_train, df_val, df_test):\n",
    "    \"\"\"\n",
    "    Reports the proportion of missing values per feature and per row for\n",
    "    training, validation, test, and combined datasets.\n",
    "\n",
    "    Args:\n",
    "        df_train: The preprocessed training set as a DataFrame.\n",
    "        df_val: The preprocessed validation set as a DataFrame.\n",
    "        df_test: The preprocessed test set as a DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with missing value statistics for training, validation,\n",
    "        test, and combined datasets.\n",
    "    \"\"\"\n",
    "    # Combine datasets\n",
    "    df_combined = pd.concat([df_train, df_val, df_test], ignore_index=True)\n",
    "\n",
    "    # Helper function to calculate missing value statistics\n",
    "    def calculate_missing_stats(df, name):\n",
    "        perc_missing_per_ftr = df.isnull().sum(axis=0) / df.shape[0]\n",
    "        frac_missing_rows = (df.isnull().sum(axis=1) != 0).mean()\n",
    "        return {\n",
    "            'feature_missing_proportion': perc_missing_per_ftr[perc_missing_per_ftr > 0],\n",
    "            'row_missing_proportion': frac_missing_rows\n",
    "        }\n",
    "\n",
    "    # Calculate missing value statistics\n",
    "    missing_stats = {\n",
    "        'training': calculate_missing_stats(df_train, 'Training'),\n",
    "        'validation': calculate_missing_stats(df_val, 'Validation'),\n",
    "        'test': calculate_missing_stats(df_test, 'Test'),\n",
    "        'combined': calculate_missing_stats(df_combined, 'Combined')\n",
    "    }\n",
    "\n",
    "    # Print results\n",
    "    for dataset, stats in missing_stats.items():\n",
    "        print(f\"\\n{dataset.capitalize()} Dataset:\")\n",
    "        print(f\"Proportion of missing values per feature:\")\n",
    "        print(stats['feature_missing_proportion'])\n",
    "        print(f\"Proportion of rows with missing values: {stats['row_missing_proportion']:.4f}\")\n",
    "\n",
    "\n",
    "report_missing_values(df_train, df_val, df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Missing Value Imputation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the imputer on the training data...\n",
      "Imputing missing values in the validation and test datasets...\n",
      "Imputation complete.\n",
      "\n",
      "Training Dataset:\n",
      "Proportion of missing values per feature:\n",
      "Series([], dtype: float64)\n",
      "Proportion of rows with missing values: 0.0000\n",
      "\n",
      "Validation Dataset:\n",
      "Proportion of missing values per feature:\n",
      "Series([], dtype: float64)\n",
      "Proportion of rows with missing values: 0.0000\n",
      "\n",
      "Test Dataset:\n",
      "Proportion of missing values per feature:\n",
      "Series([], dtype: float64)\n",
      "Proportion of rows with missing values: 0.0000\n",
      "\n",
      "Combined Dataset:\n",
      "Proportion of missing values per feature:\n",
      "Series([], dtype: float64)\n",
      "Proportion of rows with missing values: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/impute/_iterative.py:825: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "\n",
    "def multivariate_imputer(X_train, X_val, X_test, random_state=42):\n",
    "    \"\"\"\n",
    "    Constructs a multivariate imputer using IterativeImputer with RandomForestRegressor \n",
    "    and imputes missing values in the provided datasets.\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Training feature matrix with missing values.\n",
    "        X_val (pd.DataFrame): Validation feature matrix with missing values.\n",
    "        X_test (pd.DataFrame): Test feature matrix with missing values.\n",
    "        random_state (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Imputed versions of X_train, X_val, X_test as DataFrames.\n",
    "    \"\"\"\n",
    "    # Initialize the IterativeImputer with RandomForestRegressor\n",
    "    imputer = IterativeImputer(\n",
    "        estimator=RandomForestRegressor(n_estimators=10, random_state=random_state),\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Fit the imputer on the training data and transform all datasets\n",
    "    print(\"Fitting the imputer on the training data...\")\n",
    "    X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "    print(\"Imputing missing values in the validation and test datasets...\")\n",
    "    X_val_imputed = pd.DataFrame(imputer.transform(X_val), columns=X_train.columns)\n",
    "    X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X_train.columns)\n",
    "    \n",
    "    print(\"Imputation complete.\")\n",
    "    return X_train_imputed, X_val_imputed, X_test_imputed\n",
    "\n",
    "X_train_imputed_mi, X_val_imputed_mi, X_test_imputed_mi = multivariate_imputer(df_train, df_val, df_test, random_state=42)\n",
    "report_missing_values(X_train_imputed_mi, X_val_imputed_mi, X_test_imputed_mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing missing values for column: num__horsepower\n",
      "Imputing missing values for column: num__displacement\n",
      "Imputing missing values for column: num__cylinders\n",
      "Imputing missing values for column: num__gears\n",
      "\n",
      "Training Dataset:\n",
      "Proportion of missing values per feature:\n",
      "Series([], dtype: float64)\n",
      "Proportion of rows with missing values: 0.0000\n",
      "\n",
      "Validation Dataset:\n",
      "Proportion of missing values per feature:\n",
      "Series([], dtype: float64)\n",
      "Proportion of rows with missing values: 0.0000\n",
      "\n",
      "Test Dataset:\n",
      "Proportion of missing values per feature:\n",
      "Series([], dtype: float64)\n",
      "Proportion of rows with missing values: 0.0000\n",
      "\n",
      "Combined Dataset:\n",
      "Proportion of missing values per feature:\n",
      "Series([], dtype: float64)\n",
      "Proportion of rows with missing values: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "def impute_with_xgboost(df_train, df_val, df_test, target_column):\n",
    "    \"\"\"\n",
    "    Imputes missing values in a single column using XGBoost.\n",
    "\n",
    "    Args:\n",
    "        df_train (pd.DataFrame): Training set with missing values.\n",
    "        df_val (pd.DataFrame): Validation set with missing values.\n",
    "        df_test (pd.DataFrame): Test set with missing values.\n",
    "        target_column (str): Column to impute.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Updated versions of df_train, df_val, and df_test.\n",
    "    \"\"\"\n",
    "    # Separate rows with and without missing values in the training set\n",
    "    train_data = df_train[df_train[target_column].notnull()]\n",
    "    missing_data_train = df_train[df_train[target_column].isnull()]\n",
    "\n",
    "    # Features and target for training\n",
    "    X_train = train_data.drop(columns=[target_column])\n",
    "    y_train = train_data[target_column]\n",
    "\n",
    "    # Features for prediction (rows with missing target values)\n",
    "    X_missing_train = missing_data_train.drop(columns=[target_column])\n",
    "    X_missing_val = df_val[df_val[target_column].isnull()].drop(columns=[target_column])\n",
    "    X_missing_test = df_test[df_test[target_column].isnull()].drop(columns=[target_column])\n",
    "\n",
    "    # Train XGBoost Regressor\n",
    "    model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict missing values in the training set\n",
    "    if not X_missing_train.empty:\n",
    "        imputed_values_train = model.predict(X_missing_train)\n",
    "        df_train.loc[df_train[target_column].isnull(), target_column] = imputed_values_train\n",
    "\n",
    "    # Predict missing values in the validation and test sets\n",
    "    if not X_missing_val.empty:\n",
    "        imputed_values_val = model.predict(X_missing_val)\n",
    "        df_val.loc[df_val[target_column].isnull(), target_column] = imputed_values_val\n",
    "\n",
    "    if not X_missing_test.empty:\n",
    "        imputed_values_test = model.predict(X_missing_test)\n",
    "        df_test.loc[df_test[target_column].isnull(), target_column] = imputed_values_test\n",
    "\n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "\n",
    "# Impute each column with missing values\n",
    "X_train_imputed_xgb = df_train.copy()\n",
    "X_val_imputed_xgb = df_val.copy()\n",
    "X_test_imputed_xgb = df_test.copy()\n",
    "\n",
    "for col in df_train.columns:\n",
    "    if (\n",
    "        X_train_imputed_xgb[col].isnull().any()\n",
    "        or X_val_imputed_xgb[col].isnull().any()\n",
    "        or X_test_imputed_xgb[col].isnull().any()\n",
    "    ):\n",
    "        print(f\"Imputing missing values for column: {col}\")\n",
    "        X_train_imputed_xgb, X_val_imputed_xgb, X_test_imputed_xgb = impute_with_xgboost(\n",
    "            X_train_imputed_xgb, X_val_imputed_xgb, X_test_imputed_xgb, col\n",
    "        )\n",
    "\n",
    "# Check missing values after imputation\n",
    "report_missing_values(X_train_imputed_xgb, X_val_imputed_xgb, X_test_imputed_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def MLpipeline(X, y, preprocessor, ML_algo, param_grid):\n",
    "    '''\n",
    "    This function splits the data into other/test (80/20) and then applies KFold with 4 folds to other.\n",
    "    It evaluates models using MAE, RMSE, and R², and records the best model for each metric.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary containing test scores (MAE, RMSE, R²) for each iteration\n",
    "    - The best model for each metric\n",
    "    '''\n",
    "\n",
    "    # Lists to store results\n",
    "    test_scores = {\n",
    "        'MAE': [],\n",
    "        'RMSE': [],\n",
    "        'R2': []\n",
    "    }\n",
    "    best_models = {\n",
    "        'MAE': None,\n",
    "        'RMSE': None,\n",
    "        'R2': None\n",
    "    }\n",
    "    best_scores = {\n",
    "        'MAE': float('inf'),\n",
    "        'RMSE': float('inf'),\n",
    "        'R2': float('-inf')\n",
    "    }\n",
    "\n",
    "    nr_states = 10\n",
    "\n",
    "    for i in range(nr_states):\n",
    "        print(f\"\\nIteration {i+1}\")\n",
    "\n",
    "        # Split data\n",
    "        X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state=42 * i)\n",
    "\n",
    "        # Create KFold object\n",
    "        kf = KFold(n_splits=4, shuffle=True, random_state=42 * i)\n",
    "\n",
    "        # Pipeline and GridSearchCV\n",
    "        pipe = make_pipeline(preprocessor, ML_algo)\n",
    "        grid = GridSearchCV(\n",
    "            pipe,\n",
    "            param_grid=param_grid,\n",
    "            scoring='neg_root_mean_squared_error',  # Primary metric for GridSearch\n",
    "            cv=kf,\n",
    "            return_train_score=True,\n",
    "            n_jobs=-1,\n",
    "            verbose=True\n",
    "        )\n",
    "        grid.fit(X_other, y_other)\n",
    "\n",
    "        # Save the best model\n",
    "        best_model = grid.best_estimator_\n",
    "        print('Best model parameters:', grid.best_params_)\n",
    "        print('Validation score (RMSE):', -grid.best_score_)\n",
    "\n",
    "        # Predictions and metrics on the test set\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "        test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "        test_rmse = root_mean_squared_error(y_test, y_test_pred)  # RMSE\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "        print('Test MAE:', test_mae)\n",
    "        print('Test RMSE:', test_rmse)\n",
    "        print('Test R²:', test_r2)\n",
    "\n",
    "        # Append test scores\n",
    "        test_scores['MAE'].append(test_mae)\n",
    "        test_scores['RMSE'].append(test_rmse)\n",
    "        test_scores['R2'].append(test_r2)\n",
    "\n",
    "        # Update best models\n",
    "        if test_mae < best_scores['MAE']:\n",
    "            best_scores['MAE'] = test_mae\n",
    "            best_models['MAE'] = best_model\n",
    "\n",
    "        if test_rmse < best_scores['RMSE']:\n",
    "            best_scores['RMSE'] = test_rmse\n",
    "            best_models['RMSE'] = best_model\n",
    "\n",
    "        if test_r2 > best_scores['R2']:\n",
    "            best_scores['R2'] = test_r2\n",
    "            best_models['R2'] = best_model\n",
    "\n",
    "    # Return results\n",
    "    return test_scores, best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Lasso\n",
      "\n",
      "Iteration 1\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 20 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n20 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py\", line 980, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1064, in check_array\n    _assert_all_finite(\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLasso does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 53\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 53\u001b[0m     test_scores, best_models \u001b[38;5;241m=\u001b[39m \u001b[43mMLpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocessor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grids\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# Calculate metrics\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     mean_mae \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(test_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[10], line 54\u001b[0m, in \u001b[0;36mMLpipeline\u001b[0;34m(X, y, preprocessor, ML_algo, param_grid)\u001b[0m\n\u001b[1;32m     44\u001b[0m pipe \u001b[38;5;241m=\u001b[39m make_pipeline(preprocessor, ML_algo)\n\u001b[1;32m     45\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     46\u001b[0m     pipe,\n\u001b[1;32m     47\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     53\u001b[0m )\n\u001b[0;32m---> 54\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_other\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_other\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Save the best model\u001b[39;00m\n\u001b[1;32m     57\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m~/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1014\u001b[0m     )\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1018\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1572\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:995\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    993\u001b[0m     )\n\u001b[0;32m--> 995\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 20 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n20 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py\", line 980, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1064, in check_array\n    _assert_all_finite(\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/home/lshiyu/anaconda3/envs/data1030_env/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLasso does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Parameter grids\n",
    "param_grids = {\n",
    "    'Lasso': {'lasso__alpha': [0.01, 0.1, 1, 10, 100]},\n",
    "    'Ridge': {'ridge__alpha': [0.01, 0.1, 1, 10, 100]},\n",
    "    'ElasticNet': {\n",
    "        'elasticnet__alpha': [0.01, 0.1, 1, 10, 100],\n",
    "        'elasticnet__l1_ratio': [0.2, 0.4, 0.6, 0.8]\n",
    "    },\n",
    "    'RandomForestRegressor': {\n",
    "        'randomforestregressor__max_depth': [1, 3, 10, 30, 100],\n",
    "        'randomforestregressor__max_features': [0.25, 0.5, 0.75, 1.0]\n",
    "    },\n",
    "    'SVR': {\n",
    "        'svr__C': [0.1, 1, 10, 100],\n",
    "        'svr__epsilon': [0.1, 0.2, 0.5],\n",
    "        'svr__kernel': ['linear', 'rbf'],\n",
    "        'svr__gamma': ['scale', 'auto', 0.01, 0.1, 1]\n",
    "    },\n",
    "    'KNeighborsRegressor': {\n",
    "        'kneighborsregressor__n_neighbors': [3, 5, 10, 20],\n",
    "        'kneighborsregressor__weights': ['uniform', 'distance']\n",
    "    },\n",
    "    'XGBRegressor': {\n",
    "        'classifier__n_estimators': [50, 100, 150],\n",
    "        'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'classifier__max_depth': [3, 5, 7]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Models to train\n",
    "models = {\n",
    "    'Lasso': Lasso(),\n",
    "    'Ridge': Ridge(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'RandomForestRegressor': RandomForestRegressor(random_state=42),\n",
    "    'SVR': SVR(),\n",
    "    'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "    'XGBRegressor': XGBRegressor()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Training pipeline\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining {model_name}\")\n",
    "    test_scores, best_models = MLpipeline(X, y, preprocessor, model, param_grids[model_name])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mean_mae = np.mean(test_scores['MAE'])\n",
    "    std_mae = np.std(test_scores['MAE'])\n",
    "    mean_rmse = np.mean(test_scores['RMSE'])\n",
    "    std_rmse = np.std(test_scores['RMSE'])\n",
    "    mean_r2 = np.mean(test_scores['R2'])\n",
    "    std_r2 = np.std(test_scores['R2'])\n",
    "\n",
    "    # Store results\n",
    "    results[model_name] = {\n",
    "        'mean_mae': mean_mae,\n",
    "        'std_mae': std_mae,\n",
    "        'mean_rmse': mean_rmse,\n",
    "        'std_rmse': std_rmse,\n",
    "        'mean_r2': mean_r2,\n",
    "        'std_r2': std_r2,\n",
    "        'best_models': best_models\n",
    "    }\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"\\n{model_name} Metrics:\")\n",
    "    print(f\"Mean MAE: {mean_mae:.4f}, Std MAE: {std_mae:.4f}\")\n",
    "    print(f\"Mean RMSE: {mean_rmse:.4f}, Std RMSE: {std_rmse:.4f}\")\n",
    "    print(f\"Mean R²: {mean_r2:.4f}, Std R²: {std_r2:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
