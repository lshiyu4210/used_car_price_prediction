{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4009, 14)\n"
     ]
    }
   ],
   "source": [
    "# Import Data\n",
    "import pandas as pd\n",
    "\n",
    "new_used_car = pd.read_csv(\"../data/processed_used_car.csv\")\n",
    "random_state = 42\n",
    "\n",
    "y = new_used_car['sales_price_log']\n",
    "X = new_used_car.drop(['price', 'sales_price_log','model'], axis=1)     # XGB\n",
    "# X = new_used_car.drop(['price', 'sales_price_log', 'model', 'int_col', 'ext_col'], axis=1)    # Multivariate Imputation\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: brand, Data Type: object\n",
      "Column: model_year, Data Type: int64\n",
      "Column: milage, Data Type: int64\n",
      "Column: fuel_type, Data Type: object\n",
      "Column: ext_col, Data Type: object\n",
      "Column: int_col, Data Type: object\n",
      "Column: accident, Data Type: object\n",
      "Column: clean_title, Data Type: object\n",
      "Column: horsepower, Data Type: float64\n",
      "Column: displacement, Data Type: float64\n",
      "Column: cylinders, Data Type: float64\n",
      "Column: turbo, Data Type: bool\n",
      "Column: transmission_type, Data Type: object\n",
      "Column: gears, Data Type: float64\n"
     ]
    }
   ],
   "source": [
    "# Data types of features\n",
    "for column in X.columns:\n",
    "    print(f\"Column: {column}, Data Type: {new_used_car[column].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction of missing values in features:\n",
      "fuel_type            0.054128\n",
      "accident             0.028187\n",
      "clean_title          0.148666\n",
      "horsepower           0.201547\n",
      "displacement         0.054128\n",
      "cylinders            0.109753\n",
      "transmission_type    0.121976\n",
      "gears                0.457221\n",
      "dtype: float64\n",
      "data types of the features with missing values:\n",
      "fuel_type             object\n",
      "accident              object\n",
      "clean_title           object\n",
      "horsepower           float64\n",
      "displacement         float64\n",
      "cylinders            float64\n",
      "transmission_type     object\n",
      "gears                float64\n",
      "dtype: object\n",
      "fraction of points with missing values: 0.6083811424295336\n"
     ]
    }
   ],
   "source": [
    "# Inspect Missing Values\n",
    "perc_missing_per_ftr = new_used_car.isnull().sum(axis=0)/new_used_car.shape[0]\n",
    "print('fraction of missing values in features:')\n",
    "print(perc_missing_per_ftr[perc_missing_per_ftr > 0])\n",
    "print('data types of the features with missing values:')\n",
    "print(new_used_car[perc_missing_per_ftr[perc_missing_per_ftr > 0].index].dtypes)\n",
    "frac_missing = sum(new_used_car.isnull().sum(axis=1)!=0)/new_used_car.shape[0]\n",
    "print('fraction of points with missing values:',frac_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3207, 14)\n",
      "(802, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split to train, CV, and test\n",
    "X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "print(X_other.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "# Save y for ML models\n",
    "y_other_series = pd.Series(y_other, name=\"y_other\")\n",
    "y_other_series.to_csv(\"../data/y_other.csv\", index=False)\n",
    "y_test_series = pd.Series(y_test, name=\"y_test\")\n",
    "y_test_series.to_csv(\"../data/y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group features into numerical and categorical variables\n",
    "num_ftrs = ['model_year', 'milage', 'horsepower', 'displacement', 'cylinders', 'turbo', 'gears']\n",
    "cat_ftrs = ['brand', 'fuel_type', 'ext_col', 'int_col', 'accident', 'clean_title', 'transmission_type']     # XGB\n",
    "# cat_ftrs = ['brand', 'fuel_type', 'accident', 'clean_title', 'transmission_type']     # Multivariate Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Preprocess\n",
    "# one-hot encoder for categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(sparse_output=False,handle_unknown='ignore'))])\n",
    "\n",
    "# standard scaler for numerical variables\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# collect the transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_ftrs),\n",
    "        ('cat', categorical_transformer, cat_ftrs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set after preprocessing: (3207, 483)\n",
      "Shape of test set after preprocessing: (802, 483)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Fit-transform training set\n",
    "X_prep = preprocessor.fit_transform(X_other)\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "df_other = pd.DataFrame(data=X_prep, columns=feature_names)\n",
    "\n",
    "# Transform validation and test sets\n",
    "df_test = pd.DataFrame(data=preprocessor.transform(X_test), columns=feature_names)\n",
    "\n",
    "# Print shapes of the datasets\n",
    "print(f\"Shape of training set after preprocessing: {df_other.shape}\")\n",
    "print(f\"Shape of test set after preprocessing: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Dataset:\n",
      "Proportion of missing values per feature:\n",
      "num__horsepower      0.197381\n",
      "num__displacement    0.050514\n",
      "num__cylinders       0.106330\n",
      "num__gears           0.455254\n",
      "dtype: float64\n",
      "Proportion of rows with missing values: 0.5893\n",
      "\n",
      "Test Dataset:\n",
      "Proportion of missing values per feature:\n",
      "num__horsepower      0.218204\n",
      "num__displacement    0.068579\n",
      "num__cylinders       0.123441\n",
      "num__gears           0.465087\n",
      "dtype: float64\n",
      "Proportion of rows with missing values: 0.6209\n",
      "\n",
      "Combined Dataset:\n",
      "Proportion of missing values per feature:\n",
      "num__horsepower      0.201547\n",
      "num__displacement    0.054128\n",
      "num__cylinders       0.109753\n",
      "num__gears           0.457221\n",
      "dtype: float64\n",
      "Proportion of rows with missing values: 0.5957\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def report_missing_values(df_other, df_test):\n",
    "    \"\"\"\n",
    "    Reports the proportion of missing values per feature and per row for\n",
    "    training, validation, test, and combined datasets.\n",
    "\n",
    "    Args:\n",
    "        df_train: The preprocessed training set as a DataFrame.\n",
    "        df_val: The preprocessed validation set as a DataFrame.\n",
    "        df_test: The preprocessed test set as a DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with missing value statistics for training, validation,\n",
    "        test, and combined datasets.\n",
    "    \"\"\"\n",
    "    # Combine datasets\n",
    "    df_combined = pd.concat([df_other, df_test], ignore_index=True)\n",
    "\n",
    "    # Helper function to calculate missing value statistics\n",
    "    def calculate_missing_stats(df, name):\n",
    "        perc_missing_per_ftr = df.isnull().sum(axis=0) / df.shape[0]\n",
    "        frac_missing_rows = (df.isnull().sum(axis=1) != 0).mean()\n",
    "        return {\n",
    "            'feature_missing_proportion': perc_missing_per_ftr[perc_missing_per_ftr > 0],\n",
    "            'row_missing_proportion': frac_missing_rows\n",
    "        }\n",
    "\n",
    "    # Calculate missing value statistics\n",
    "    missing_stats = {\n",
    "        'training': calculate_missing_stats(df_other, 'Training'),\n",
    "        'test': calculate_missing_stats(df_test, 'Test'),\n",
    "        'combined': calculate_missing_stats(df_combined, 'Combined')\n",
    "    }\n",
    "\n",
    "    # Print results\n",
    "    for dataset, stats in missing_stats.items():\n",
    "        print(f\"\\n{dataset.capitalize()} Dataset:\")\n",
    "        print(f\"Proportion of missing values per feature:\")\n",
    "        print(stats['feature_missing_proportion'])\n",
    "        print(f\"Proportion of rows with missing values: {stats['row_missing_proportion']:.4f}\")\n",
    "\n",
    "\n",
    "report_missing_values(df_other, df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Missing Value Imputation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "\n",
    "def multivariate_imputer(X_other, X_test, random_state=42):\n",
    "    \"\"\"\n",
    "    Constructs a multivariate imputer using IterativeImputer with RandomForestRegressor \n",
    "    and imputes missing values in the provided datasets.\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Training feature matrix with missing values.\n",
    "        X_val (pd.DataFrame): Validation feature matrix with missing values.\n",
    "        X_test (pd.DataFrame): Test feature matrix with missing values.\n",
    "        random_state (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Imputed versions of X_train, X_val, X_test as DataFrames.\n",
    "    \"\"\"\n",
    "    # Initialize the IterativeImputer with RandomForestRegressor\n",
    "    imputer = IterativeImputer(\n",
    "        estimator=RandomForestRegressor(n_estimators=10, random_state=random_state),\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Fit the imputer on the training data and transform all datasets\n",
    "    print(\"Fitting the imputer on the training data...\")\n",
    "    X_other_imputed = pd.DataFrame(imputer.fit_transform(X_other), columns=X_other.columns)\n",
    "    print(\"Imputing missing values in the test datasets...\")\n",
    "    X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X_other.columns)\n",
    "    \n",
    "    print(\"Imputation complete.\")\n",
    "    return X_other_imputed, X_test_imputed\n",
    "\n",
    "X_other_imputed_mi, X_test_imputed_mi = multivariate_imputer(df_other, df_test, random_state=42)\n",
    "report_missing_values(X_other_imputed_mi, X_test_imputed_mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing missing values for column: num__horsepower\n",
      "Imputing missing values for column: num__displacement\n",
      "Imputing missing values for column: num__cylinders\n",
      "Imputing missing values for column: num__gears\n",
      "\n",
      "Training Dataset:\n",
      "Proportion of missing values per feature:\n",
      "Series([], dtype: float64)\n",
      "Proportion of rows with missing values: 0.0000\n",
      "\n",
      "Test Dataset:\n",
      "Proportion of missing values per feature:\n",
      "Series([], dtype: float64)\n",
      "Proportion of rows with missing values: 0.0000\n",
      "\n",
      "Combined Dataset:\n",
      "Proportion of missing values per feature:\n",
      "Series([], dtype: float64)\n",
      "Proportion of rows with missing values: 0.0000\n",
      "Imputed training data saved to results/X_other_imputed_xgb.csv\n",
      "Imputed test data saved to results/X_test_imputed_xgb.csv\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "def impute_with_xgboost(df_other, df_test, target_column):\n",
    "    \"\"\"\n",
    "    Imputes missing values in a single column using XGBoost.\n",
    "\n",
    "    Args:\n",
    "        df_train (pd.DataFrame): Training set with missing values.\n",
    "        df_val (pd.DataFrame): Validation set with missing values.\n",
    "        df_test (pd.DataFrame): Test set with missing values.\n",
    "        target_column (str): Column to impute.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Updated versions of df_train, df_val, and df_test.\n",
    "    \"\"\"\n",
    "    # Separate rows with and without missing values in the training set\n",
    "    train_data = df_other[df_other[target_column].notnull()]\n",
    "    missing_data_other = df_other[df_other[target_column].isnull()]\n",
    "\n",
    "    # Features and target for training\n",
    "    X_other = train_data.drop(columns=[target_column])\n",
    "    y_other = train_data[target_column]\n",
    "\n",
    "    # Features for prediction (rows with missing target values)\n",
    "    X_missing_train = missing_data_other.drop(columns=[target_column])\n",
    "    X_missing_test = df_test[df_test[target_column].isnull()].drop(columns=[target_column])\n",
    "\n",
    "    # Train XGBoost Regressor\n",
    "    model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "    model.fit(X_other, y_other)\n",
    "\n",
    "    # Predict missing values in the training set\n",
    "    if not X_missing_train.empty:\n",
    "        imputed_values_train = model.predict(X_missing_train)\n",
    "        df_other.loc[df_other[target_column].isnull(), target_column] = imputed_values_train\n",
    "\n",
    "    # Predict missing values in the test sets\n",
    "    if not X_missing_test.empty:\n",
    "        imputed_values_test = model.predict(X_missing_test)\n",
    "        df_test.loc[df_test[target_column].isnull(), target_column] = imputed_values_test\n",
    "\n",
    "    return df_other, df_test\n",
    "\n",
    "\n",
    "# Impute each column with missing values\n",
    "X_other_imputed_xgb = df_other.copy()\n",
    "X_test_imputed_xgb = df_test.copy()\n",
    "\n",
    "for col in df_other.columns:\n",
    "    if (\n",
    "        X_other_imputed_xgb[col].isnull().any()\n",
    "        or X_test_imputed_xgb[col].isnull().any()\n",
    "    ):\n",
    "        print(f\"Imputing missing values for column: {col}\")\n",
    "        X_other_imputed_xgb, X_test_imputed_xgb = impute_with_xgboost(\n",
    "            X_other_imputed_xgb, X_test_imputed_xgb, col\n",
    "        )\n",
    "\n",
    "# Check missing values after imputation\n",
    "report_missing_values(X_other_imputed_xgb, X_test_imputed_xgb)\n",
    "\n",
    "# Save imputed training data to CSV\n",
    "X_other_imputed_xgb.to_csv(\"../data/X_other_imputed_xgb.csv\", index=False)\n",
    "print(\"Imputed training data saved to results/X_other_imputed_xgb.csv\")\n",
    "\n",
    "# Save imputed test data to CSV\n",
    "X_test_imputed_xgb.to_csv(\"../data/X_test_imputed_xgb.csv\", index=False)\n",
    "print(\"Imputed test data saved to results/X_test_imputed_xgb.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
