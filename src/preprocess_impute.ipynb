{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4009, 14)\n"
     ]
    }
   ],
   "source": [
    "# Import Data\n",
    "import pandas as pd\n",
    "\n",
    "new_used_car = pd.read_csv(\"../data/processed_used_car.csv\")\n",
    "random_state = 42\n",
    "\n",
    "y = new_used_car['sales_price_log']\n",
    "X = new_used_car.drop(['price', 'sales_price_log','model'], axis=1)\n",
    "# X = new_used_car.drop(['price', 'sales_price_log', 'model', 'int_col', 'ext_col'], axis=1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: brand, Data Type: object\n",
      "Column: model_year, Data Type: int64\n",
      "Column: milage, Data Type: int64\n",
      "Column: fuel_type, Data Type: object\n",
      "Column: ext_col, Data Type: object\n",
      "Column: int_col, Data Type: object\n",
      "Column: accident, Data Type: object\n",
      "Column: clean_title, Data Type: object\n",
      "Column: horsepower, Data Type: float64\n",
      "Column: displacement, Data Type: float64\n",
      "Column: cylinders, Data Type: float64\n",
      "Column: turbo, Data Type: bool\n",
      "Column: transmission_type, Data Type: object\n",
      "Column: gears, Data Type: float64\n"
     ]
    }
   ],
   "source": [
    "# Data types of features\n",
    "for column in X.columns:\n",
    "    print(f\"Column: {column}, Data Type: {new_used_car[column].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction of missing values in features:\n",
      "fuel_type            0.054128\n",
      "accident             0.028187\n",
      "clean_title          0.148666\n",
      "horsepower           0.201547\n",
      "displacement         0.054128\n",
      "cylinders            0.109753\n",
      "transmission_type    0.121976\n",
      "gears                0.457221\n",
      "dtype: float64\n",
      "data types of the features with missing values:\n",
      "fuel_type             object\n",
      "accident              object\n",
      "clean_title           object\n",
      "horsepower           float64\n",
      "displacement         float64\n",
      "cylinders            float64\n",
      "transmission_type     object\n",
      "gears                float64\n",
      "dtype: object\n",
      "fraction of points with missing values: 0.6083811424295336\n"
     ]
    }
   ],
   "source": [
    "# Inspect Missing Values\n",
    "perc_missing_per_ftr = new_used_car.isnull().sum(axis=0)/new_used_car.shape[0]\n",
    "print('fraction of missing values in features:')\n",
    "print(perc_missing_per_ftr[perc_missing_per_ftr > 0])\n",
    "print('data types of the features with missing values:')\n",
    "print(new_used_car[perc_missing_per_ftr[perc_missing_per_ftr > 0].index].dtypes)\n",
    "frac_missing = sum(new_used_car.isnull().sum(axis=1)!=0)/new_used_car.shape[0]\n",
    "print('fraction of points with missing values:',frac_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3207, 14)\n",
      "(802, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split to train, CV, and test\n",
    "X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "print(X_other.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "# Save y for ML models\n",
    "y_other_series = pd.Series(y_other, name=\"y_other\")\n",
    "y_other_series.to_csv(\"../data/y_other.csv\", index=False)\n",
    "y_test_series = pd.Series(y_test, name=\"y_test\")\n",
    "y_test_series.to_csv(\"../data/y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group features into numerical and categorical variables\n",
    "num_ftrs = ['model_year', 'milage', 'horsepower', 'displacement', 'cylinders', 'turbo', 'gears']\n",
    "# cat_ftrs = ['brand', 'fuel_type', 'accident', 'clean_title', 'transmission_type']\n",
    "cat_ftrs = ['brand', 'fuel_type', 'ext_col', 'int_col', 'accident', 'clean_title', 'transmission_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Preprocess\n",
    "# one-hot encoder for categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(sparse_output=False,handle_unknown='ignore'))])\n",
    "\n",
    "# standard scaler for numerical variables\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# collect the transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_ftrs),\n",
    "        ('cat', categorical_transformer, cat_ftrs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set after preprocessing: (3207, 483)\n",
      "Shape of test set after preprocessing: (802, 483)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Fit-transform training set\n",
    "X_prep = preprocessor.fit_transform(X_other)\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "df_other = pd.DataFrame(data=X_prep, columns=feature_names)\n",
    "\n",
    "# Transform validation and test sets\n",
    "df_test = pd.DataFrame(data=preprocessor.transform(X_test), columns=feature_names)\n",
    "\n",
    "# Print shapes of the datasets\n",
    "print(f\"Shape of training set after preprocessing: {df_other.shape}\")\n",
    "print(f\"Shape of test set after preprocessing: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Dataset:\n",
      "Proportion of missing values per feature:\n",
      "num__horsepower      0.197381\n",
      "num__displacement    0.050514\n",
      "num__cylinders       0.106330\n",
      "num__gears           0.455254\n",
      "dtype: float64\n",
      "Proportion of rows with missing values: 0.5893\n",
      "\n",
      "Test Dataset:\n",
      "Proportion of missing values per feature:\n",
      "num__horsepower      0.218204\n",
      "num__displacement    0.068579\n",
      "num__cylinders       0.123441\n",
      "num__gears           0.465087\n",
      "dtype: float64\n",
      "Proportion of rows with missing values: 0.6209\n",
      "\n",
      "Combined Dataset:\n",
      "Proportion of missing values per feature:\n",
      "num__horsepower      0.201547\n",
      "num__displacement    0.054128\n",
      "num__cylinders       0.109753\n",
      "num__gears           0.457221\n",
      "dtype: float64\n",
      "Proportion of rows with missing values: 0.5957\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def report_missing_values(df_other, df_test):\n",
    "    \"\"\"\n",
    "    Reports the proportion of missing values per feature and per row for\n",
    "    training, validation, test, and combined datasets.\n",
    "\n",
    "    Args:\n",
    "        df_train: The preprocessed training set as a DataFrame.\n",
    "        df_val: The preprocessed validation set as a DataFrame.\n",
    "        df_test: The preprocessed test set as a DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with missing value statistics for training, validation,\n",
    "        test, and combined datasets.\n",
    "    \"\"\"\n",
    "    # Combine datasets\n",
    "    df_combined = pd.concat([df_other, df_test], ignore_index=True)\n",
    "\n",
    "    # Helper function to calculate missing value statistics\n",
    "    def calculate_missing_stats(df, name):\n",
    "        perc_missing_per_ftr = df.isnull().sum(axis=0) / df.shape[0]\n",
    "        frac_missing_rows = (df.isnull().sum(axis=1) != 0).mean()\n",
    "        return {\n",
    "            'feature_missing_proportion': perc_missing_per_ftr[perc_missing_per_ftr > 0],\n",
    "            'row_missing_proportion': frac_missing_rows\n",
    "        }\n",
    "\n",
    "    # Calculate missing value statistics\n",
    "    missing_stats = {\n",
    "        'training': calculate_missing_stats(df_other, 'Training'),\n",
    "        'test': calculate_missing_stats(df_test, 'Test'),\n",
    "        'combined': calculate_missing_stats(df_combined, 'Combined')\n",
    "    }\n",
    "\n",
    "    # Print results\n",
    "    for dataset, stats in missing_stats.items():\n",
    "        print(f\"\\n{dataset.capitalize()} Dataset:\")\n",
    "        print(f\"Proportion of missing values per feature:\")\n",
    "        print(stats['feature_missing_proportion'])\n",
    "        print(f\"Proportion of rows with missing values: {stats['row_missing_proportion']:.4f}\")\n",
    "\n",
    "\n",
    "report_missing_values(df_other, df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Missing Value Imputation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "\n",
    "def multivariate_imputer(X_other, X_test, random_state=42):\n",
    "    \"\"\"\n",
    "    Constructs a multivariate imputer using IterativeImputer with RandomForestRegressor \n",
    "    and imputes missing values in the provided datasets.\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Training feature matrix with missing values.\n",
    "        X_val (pd.DataFrame): Validation feature matrix with missing values.\n",
    "        X_test (pd.DataFrame): Test feature matrix with missing values.\n",
    "        random_state (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Imputed versions of X_train, X_val, X_test as DataFrames.\n",
    "    \"\"\"\n",
    "    # Initialize the IterativeImputer with RandomForestRegressor\n",
    "    imputer = IterativeImputer(\n",
    "        estimator=RandomForestRegressor(n_estimators=10, random_state=random_state),\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Fit the imputer on the training data and transform all datasets\n",
    "    print(\"Fitting the imputer on the training data...\")\n",
    "    X_other_imputed = pd.DataFrame(imputer.fit_transform(X_other), columns=X_other.columns)\n",
    "    print(\"Imputing missing values in the test datasets...\")\n",
    "    X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X_other.columns)\n",
    "    \n",
    "    print(\"Imputation complete.\")\n",
    "    return X_other_imputed, X_test_imputed\n",
    "\n",
    "X_other_imputed_mi, X_test_imputed_mi = multivariate_imputer(df_other, df_test, random_state=42)\n",
    "report_missing_values(X_other_imputed_mi, X_test_imputed_mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing missing values for column: num__horsepower\n",
      "Imputing missing values for column: num__displacement\n",
      "Imputing missing values for column: num__cylinders\n",
      "Imputing missing values for column: num__gears\n",
      "\n",
      "Training Dataset:\n",
      "Proportion of missing values per feature:\n",
      "Series([], dtype: float64)\n",
      "Proportion of rows with missing values: 0.0000\n",
      "\n",
      "Test Dataset:\n",
      "Proportion of missing values per feature:\n",
      "Series([], dtype: float64)\n",
      "Proportion of rows with missing values: 0.0000\n",
      "\n",
      "Combined Dataset:\n",
      "Proportion of missing values per feature:\n",
      "Series([], dtype: float64)\n",
      "Proportion of rows with missing values: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "def impute_with_xgboost(df_other, df_test, target_column):\n",
    "    \"\"\"\n",
    "    Imputes missing values in a single column using XGBoost.\n",
    "\n",
    "    Args:\n",
    "        df_train (pd.DataFrame): Training set with missing values.\n",
    "        df_val (pd.DataFrame): Validation set with missing values.\n",
    "        df_test (pd.DataFrame): Test set with missing values.\n",
    "        target_column (str): Column to impute.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Updated versions of df_train, df_val, and df_test.\n",
    "    \"\"\"\n",
    "    # Separate rows with and without missing values in the training set\n",
    "    train_data = df_other[df_other[target_column].notnull()]\n",
    "    missing_data_other = df_other[df_other[target_column].isnull()]\n",
    "\n",
    "    # Features and target for training\n",
    "    X_other = train_data.drop(columns=[target_column])\n",
    "    y_other = train_data[target_column]\n",
    "\n",
    "    # Features for prediction (rows with missing target values)\n",
    "    X_missing_train = missing_data_other.drop(columns=[target_column])\n",
    "    X_missing_test = df_test[df_test[target_column].isnull()].drop(columns=[target_column])\n",
    "\n",
    "    # Train XGBoost Regressor\n",
    "    model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "    model.fit(X_other, y_other)\n",
    "\n",
    "    # Predict missing values in the training set\n",
    "    if not X_missing_train.empty:\n",
    "        imputed_values_train = model.predict(X_missing_train)\n",
    "        df_other.loc[df_other[target_column].isnull(), target_column] = imputed_values_train\n",
    "\n",
    "    # Predict missing values in the test sets\n",
    "    if not X_missing_test.empty:\n",
    "        imputed_values_test = model.predict(X_missing_test)\n",
    "        df_test.loc[df_test[target_column].isnull(), target_column] = imputed_values_test\n",
    "\n",
    "    return df_other, df_test\n",
    "\n",
    "\n",
    "# Impute each column with missing values\n",
    "X_other_imputed_xgb = df_other.copy()\n",
    "X_test_imputed_xgb = df_test.copy()\n",
    "\n",
    "for col in df_other.columns:\n",
    "    if (\n",
    "        X_other_imputed_xgb[col].isnull().any()\n",
    "        or X_test_imputed_xgb[col].isnull().any()\n",
    "    ):\n",
    "        print(f\"Imputing missing values for column: {col}\")\n",
    "        X_other_imputed_xgb, X_test_imputed_xgb = impute_with_xgboost(\n",
    "            X_other_imputed_xgb, X_test_imputed_xgb, col\n",
    "        )\n",
    "\n",
    "# Check missing values after imputation\n",
    "report_missing_values(X_other_imputed_xgb, X_test_imputed_xgb)\n",
    "\n",
    "# Save imputed training data to CSV\n",
    "X_other_imputed_xgb.to_csv(\"../data/X_other_imputed_xgb.csv\", index=False)\n",
    "print(\"Imputed training data saved to results/X_other_imputed_xgb.csv\")\n",
    "\n",
    "# Save imputed test data to CSV\n",
    "X_test_imputed_xgb.to_csv(\"../data/X_test_imputed_xgb.csv\", index=False)\n",
    "print(\"Imputed test data saved to results/X_test_imputed_xgb.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def MLpipeline(X_other, y_other, X_test, y_test, ML_algo, param_grid):\n",
    "    '''\n",
    "    This function directly uses the provided train, validation, and test splits.\n",
    "    It evaluates models using MAE, RMSE, and R², and records the best model for each metric.\n",
    "\n",
    "    Args:\n",
    "    - X_train, y_train: Training dataset\n",
    "    - X_val, y_val: Validation dataset for GridSearchCV\n",
    "    - X_test, y_test: Test dataset for evaluation\n",
    "    - ML_algo: Machine Learning algorithm\n",
    "    - param_grid: Parameter grid for hyperparameter tuning\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary containing test scores (MAE, RMSE, R²)\n",
    "    - The best model for each metric\n",
    "    '''\n",
    "    # Lists to store results\n",
    "    test_scores = {\n",
    "        'MAE': [],\n",
    "        'RMSE': [],\n",
    "        'R2': []\n",
    "    }\n",
    "    best_models = {\n",
    "        'MAE': None,\n",
    "        'RMSE': None,\n",
    "        'R2': None\n",
    "    }\n",
    "\n",
    "    # GridSearchCV\n",
    "    print(\"\\nPerforming GridSearchCV...\")\n",
    "    grid = GridSearchCV(\n",
    "        estimator=ML_algo,\n",
    "        param_grid=param_grid,\n",
    "        scoring='neg_root_mean_squared_error',  # Primary metric for GridSearch\n",
    "        cv=4,  # Fixed to 4-fold cross-validation\n",
    "        return_train_score=True,\n",
    "        n_jobs=-1,\n",
    "        verbose=True\n",
    "    )\n",
    "    grid.fit(X_other, y_other)\n",
    "\n",
    "    # Save the best model\n",
    "    best_model = grid.best_estimator_\n",
    "    print('Best model parameters:', grid.best_params_)\n",
    "    print('Validation score (RMSE):', -grid.best_score_)\n",
    "\n",
    "    # Predictions and metrics on the test set\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_rmse = root_mean_squared_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    print('Test MAE:', test_mae)\n",
    "    print('Test RMSE:', test_rmse)\n",
    "    print('Test R²:', test_r2)\n",
    "\n",
    "    # Store test scores\n",
    "    test_scores['MAE'] = test_mae\n",
    "    test_scores['RMSE'] = test_rmse\n",
    "    test_scores['R2'] = test_r2\n",
    "\n",
    "    # Save the best model for each metric\n",
    "    best_models['MAE'] = best_model\n",
    "    best_models['RMSE'] = best_model\n",
    "    best_models['R2'] = best_model\n",
    "\n",
    "    # Return results\n",
    "    return test_scores, best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Metrics:\n",
      "Baseline RMSE: 0.3833\n",
      "Baseline MAE: 0.2889\n",
      "Baseline R²: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "y_mean = np.mean(y_test)  # Baseline: Predict the mean for all instances\n",
    "baseline_rmse = root_mean_squared_error(y_test, [y_mean] * len(y_test))\n",
    "baseline_mae = mean_absolute_error(y_test, [y_mean] * len(y_test))\n",
    "baseline_r2 = r2_score(y_test, [y_mean] * len(y_test))\n",
    "\n",
    "print(\"Baseline Metrics:\")\n",
    "print(f\"Baseline RMSE: {baseline_rmse:.4f}\")\n",
    "print(f\"Baseline MAE: {baseline_mae:.4f}\")\n",
    "print(f\"Baseline R²: {baseline_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "model.fit(X_other_imputed_xgb, y_other)\n",
    "importances = model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_other_imputed_xgb.columns, 'Importance': importances}).sort_values(by='Importance', ascending=False)\n",
    "feature_importance_df.to_csv('feature_importance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance on Test Set:\n",
      "RMSE: 0.1627\n",
      "MAE: 0.0979\n",
      "R²: 0.8198\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score\n",
    "\n",
    "y_pred = model.predict(X_test_imputed_xgb)\n",
    "\n",
    "# Calculate metrics\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Model Performance on Test Set:\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Lasso\n",
      "\n",
      "Performing GridSearchCV...\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Best model parameters: {'alpha': 0.01}\n",
      "Validation score (RMSE): 0.17982392978408387\n",
      "Test MAE: 0.12994943746643633\n",
      "Test RMSE: 0.19827571038513128\n",
      "Test R²: 0.7323478373791811\n",
      "\n",
      "Training Ridge\n",
      "\n",
      "Performing GridSearchCV...\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Best model parameters: {'alpha': 1}\n",
      "Validation score (RMSE): 0.14728566013218672\n",
      "Test MAE: 0.11143840796739744\n",
      "Test RMSE: 0.17964958087158353\n",
      "Test R²: 0.7802726366545693\n",
      "\n",
      "Training ElasticNet\n",
      "\n",
      "Performing GridSearchCV...\n",
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
      "Best model parameters: {'alpha': 0.01, 'l1_ratio': 0.2}\n",
      "Validation score (RMSE): 0.1663927464167528\n",
      "Test MAE: 0.12036548922221313\n",
      "Test RMSE: 0.18781770822556532\n",
      "Test R²: 0.7598377179809125\n",
      "\n",
      "Training RandomForestRegressor\n",
      "\n",
      "Performing GridSearchCV...\n",
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
      "Best model parameters: {'max_depth': 100, 'max_features': 0.25}\n",
      "Validation score (RMSE): 0.13480178925007189\n",
      "Test MAE: 0.09484928158629939\n",
      "Test RMSE: 0.16071539792450878\n",
      "Test R²: 0.8241482463630853\n",
      "\n",
      "Training SVR\n",
      "\n",
      "Performing GridSearchCV...\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Best model parameters: {'C': 10, 'epsilon': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Validation score (RMSE): 0.12902906759916558\n",
      "Test MAE: 0.09852448704481148\n",
      "Test RMSE: 0.15900658399582746\n",
      "Test R²: 0.8278678700056774\n",
      "\n",
      "Training KNeighborsRegressor\n",
      "\n",
      "Performing GridSearchCV...\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'n_neighbors': 10, 'weights': 'distance'}\n",
      "Validation score (RMSE): 0.15543630474646544\n",
      "Test MAE: 0.11413968273748835\n",
      "Test RMSE: 0.1791269306864937\n",
      "Test R²: 0.7815492719258669\n",
      "\n",
      "Training XGBRegressor\n",
      "\n",
      "Performing GridSearchCV...\n",
      "Fitting 4 folds for each of 27 candidates, totalling 108 fits\n",
      "Best model parameters: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 150}\n",
      "Validation score (RMSE): 0.12618015670111005\n",
      "Test MAE: 0.09109476865106703\n",
      "Test RMSE: 0.15609912134859802\n",
      "Test R²: 0.8341052490712328\n",
      "\n",
      "Best Overall Models:\n",
      "MAE - Method: XGBRegressor, Value: 0.0911\n",
      "RMSE - Method: XGBRegressor, Value: 0.1561\n",
      "R2 - Method: XGBRegressor, Value: 0.8341\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Parameter grids\n",
    "param_grids = {\n",
    "    'Lasso': {'alpha': [0.01, 0.1, 1, 10, 100]},\n",
    "    'Ridge': {'alpha': [0.01, 0.1, 1, 10, 100]},\n",
    "    'ElasticNet': {\n",
    "        'alpha': [0.01, 0.1, 1, 10, 100],\n",
    "        'l1_ratio': [0.2, 0.4, 0.6, 0.8]\n",
    "    },\n",
    "    'RandomForestRegressor': {\n",
    "        'max_depth': [1, 3, 10, 30, 100],\n",
    "        'max_features': [0.25, 0.5, 0.75, 1.0]\n",
    "    },\n",
    "    'SVR': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'epsilon': [0.1, 0.2, 0.5],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale', 'auto', 0.01, 0.1, 1]\n",
    "    },\n",
    "    'KNeighborsRegressor': {\n",
    "        'n_neighbors': [3, 5, 10, 20],\n",
    "        'weights': ['uniform', 'distance']\n",
    "    },\n",
    "    'XGBRegressor': {\n",
    "        'n_estimators': [50, 100, 150],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Models to train\n",
    "models = {\n",
    "    'Lasso': Lasso(),\n",
    "    'Ridge': Ridge(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'RandomForestRegressor': RandomForestRegressor(random_state=42),\n",
    "    'SVR': SVR(),\n",
    "    'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "    'XGBRegressor': XGBRegressor()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "best_models_overall = {\n",
    "    'MAE': {'method': None, 'model': None, 'value': float('inf')},  # Lower is better\n",
    "    'RMSE': {'method': None, 'model': None, 'value': float('inf')},  # Lower is better\n",
    "    'R2': {'method': None, 'model': None, 'value': float('-inf')}   # Higher is better\n",
    "}\n",
    "\n",
    "# Training pipeline\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining {model_name}\")\n",
    "    test_scores, best_models = MLpipeline(\n",
    "        X_other_imputed_xgb, y_other, X_test_imputed_xgb, y_test, model, param_grids[model_name]\n",
    "    )\n",
    "    # Save detailed results for each model\n",
    "    results[model_name] = {\n",
    "        'Best Parameters': best_models['R2'].get_params(),  # Assuming best model is selected by R²\n",
    "        'Validation RMSE': -test_scores.get('Validation_RMSE', 0),  # Replace if validation RMSE available\n",
    "        'Test MAE': test_scores['MAE'],\n",
    "        'Test RMSE': test_scores['RMSE'],\n",
    "        'Test R²': test_scores['R2']\n",
    "    }\n",
    "\n",
    "    # Update best overall models for each metric\n",
    "    if test_scores['MAE'] < best_models_overall['MAE']['value']:\n",
    "        best_models_overall['MAE'] = {'method': model_name, 'model': best_models['MAE'], 'value': test_scores['MAE']}\n",
    "    if test_scores['RMSE'] < best_models_overall['RMSE']['value']:\n",
    "        best_models_overall['RMSE'] = {'method': model_name, 'model': best_models['RMSE'], 'value': test_scores['RMSE']}\n",
    "    if test_scores['R2'] > best_models_overall['R2']['value']:\n",
    "        best_models_overall['R2'] = {'method': model_name, 'model': best_models['R2'], 'value': test_scores['R2']}\n",
    "\n",
    "# Print the best overall models for each metric\n",
    "print(\"\\nBest Overall Models:\")\n",
    "for metric, info in best_models_overall.items():\n",
    "    print(f\"{metric} - Method: {info['method']}, Value: {info['value']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results as a text file\n",
    "with open(\"results/xgb_imputed_best_models_results.txt\", \"w\") as f:\n",
    "    # Write feature columns and their data types\n",
    "    f.write(\"\\nFeature Columns and Data Types:\\n\\n\")\n",
    "    for column in X.columns:\n",
    "        f.write(f\"Column: {column}, Data Type: {new_used_car[column].dtype}\\n\")\n",
    "\n",
    "    # Write detailed results for each model\n",
    "    f.write(\"Detailed Results for Each Model:\\n\\n\")\n",
    "    for model_name, result in results.items():\n",
    "        f.write(f\"Model: {model_name}\\n\")\n",
    "        f.write(f\"Best Parameters: {result['Best Parameters']}\\n\")\n",
    "        f.write(f\"Validation RMSE: {result['Validation RMSE']:.4f}\\n\")\n",
    "        f.write(f\"Test MAE: {result['Test MAE']:.4f}\\n\")\n",
    "        f.write(f\"Test RMSE: {result['Test RMSE']:.4f}\\n\")\n",
    "        f.write(f\"Test R²: {result['Test R²']:.4f}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    # Write the best overall models\n",
    "    f.write(\"Best Overall Models:\\n\")\n",
    "    for metric, info in best_models_overall.items():\n",
    "        f.write(f\"{metric} - Method: {info['method']}, Value: {info['value']:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
